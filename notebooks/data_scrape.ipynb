{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hunter S. DiCicco\n",
    "\n",
    "with Dr. Dongwon Lee, Ph.D.\n",
    "\n",
    "# Data Collection: Limited Web Scraping\n",
    "for *Promotional* and *Misreporting* Content\n",
    "\n",
    "## TODO:\n",
    "* Rectify Promotional Content/Native Ads Class Balance\n",
    "* Vectorize Human Trial Test Set\n",
    "\n",
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import requests as r\n",
    "import itertools as it\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.chdir('../')\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_DICT = dict(zip(('real', 'fake', 'opinion', 'polarized', 'satire', 'promotional', 'correction'),\n",
    "                      (1, 2, 3, 5, 7, 9, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = r.utils.default_headers()\n",
    "headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Status</th>\n",
       "      <th>Coder</th>\n",
       "      <th>Story 1</th>\n",
       "      <th>Story 2</th>\n",
       "      <th>Story 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yahoo News</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DI</td>\n",
       "      <td>https://goingthere.yahoo.com/post/133803688011...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130087715036...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130160620511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>Done</td>\n",
       "      <td>DI</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/providence-...</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Network</td>\n",
       "      <td>DONE</td>\n",
       "      <td>BWW</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/amazon/article/8...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/subaru/article/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>DONE</td>\n",
       "      <td>NJE</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>http://www.nbcnews.com/video/he-creates-furnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuffingtonPost.com</td>\n",
       "      <td>DONE</td>\n",
       "      <td>BWW</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/06/04/best-...</td>\n",
       "      <td>http://www.huffingtonpost.com/kathy-magee/a-sm...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/05/29/evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site Status Coder  \\\n",
       "0          Yahoo News   DONE    DI   \n",
       "1         ABC News \\n   Done    DI   \n",
       "2         CNN Network   DONE   BWW   \n",
       "3    NBC News Digital   DONE   NJE   \n",
       "4  HuffingtonPost.com   DONE   BWW   \n",
       "\n",
       "                                             Story 1  \\\n",
       "0  https://goingthere.yahoo.com/post/133803688011...   \n",
       "1  http://abcnews.go.com/US/wireStory/providence-...   \n",
       "2  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  http://www.huffingtonpost.com/2015/06/04/best-...   \n",
       "\n",
       "                                             Story 2  \\\n",
       "0  https://goingthere.yahoo.com/post/130087715036...   \n",
       "1  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "2  http://sponsorcontent.cnn.com/amazon/article/8...   \n",
       "3  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "4  http://www.huffingtonpost.com/kathy-magee/a-sm...   \n",
       "\n",
       "                                             Story 3  \n",
       "0  https://goingthere.yahoo.com/post/130160620511...  \n",
       "1  http://abcnews.go.com/Politics/justice-antonin...  \n",
       "2  http://sponsorcontent.cnn.com/subaru/article/a...  \n",
       "3  http://www.nbcnews.com/video/he-creates-furnit...  \n",
       "4  http://www.huffingtonpost.com/2015/05/29/evolu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = pd.read_excel(\"data/Nativead.xlsx\")\n",
    "nativead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/release-of-the-united-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/conclusion-of-negotiatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/u-s-mexico-joint-declara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/united-states-restricts-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/president-donald-j-trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source                                               URLs\n",
       "0  U.S. Department of State  https://www.state.gov/release-of-the-united-st...\n",
       "1  U.S. Department of State  https://www.state.gov/conclusion-of-negotiatio...\n",
       "2  U.S. Department of State  https://www.state.gov/u-s-mexico-joint-declara...\n",
       "3  U.S. Department of State  https://www.state.gov/united-states-restricts-...\n",
       "4  U.S. Department of State  https://www.state.gov/president-donald-j-trump..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo = pd.read_excel(\"data/PR_content_news.xlsx\")\n",
    "promo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DONE                38\n",
       "Done                 5\n",
       "N/A, now defunct     1\n",
       "Found only 1         1\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site       0\n",
       "Status     0\n",
       "Coder      0\n",
       "Story 1    0\n",
       "Story 2    0\n",
       "Story 3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = nativead.astype(str)\n",
    "nativead = nativead[nativead['Status'].apply(str.lower)=='done']\n",
    "nativead.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Story 1</th>\n",
       "      <th>Story 2</th>\n",
       "      <th>Story 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yahoo News</td>\n",
       "      <td>https://goingthere.yahoo.com/post/133803688011...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130087715036...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130160620511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/providence-...</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Network</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/amazon/article/8...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/subaru/article/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>http://www.nbcnews.com/video/he-creates-furnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuffingtonPost.com</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/06/04/best-...</td>\n",
       "      <td>http://www.huffingtonpost.com/kathy-magee/a-sm...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/05/29/evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site                                            Story 1  \\\n",
       "0          Yahoo News  https://goingthere.yahoo.com/post/133803688011...   \n",
       "1         ABC News \\n  http://abcnews.go.com/US/wireStory/providence-...   \n",
       "2         CNN Network  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3    NBC News Digital  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  HuffingtonPost.com  http://www.huffingtonpost.com/2015/06/04/best-...   \n",
       "\n",
       "                                             Story 2  \\\n",
       "0  https://goingthere.yahoo.com/post/130087715036...   \n",
       "1  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "2  http://sponsorcontent.cnn.com/amazon/article/8...   \n",
       "3  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "4  http://www.huffingtonpost.com/kathy-magee/a-sm...   \n",
       "\n",
       "                                             Story 3  \n",
       "0  https://goingthere.yahoo.com/post/130160620511...  \n",
       "1  http://abcnews.go.com/Politics/justice-antonin...  \n",
       "2  http://sponsorcontent.cnn.com/subaru/article/a...  \n",
       "3  http://www.nbcnews.com/video/he-creates-furnit...  \n",
       "4  http://www.huffingtonpost.com/2015/05/29/evolu...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = nativead.drop(['Status', 'Coder'], axis=1)\n",
    "nativead.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://paidpost.nytimes.com/vacheron/the-shape-of-harmony/elegance-of-substance.html Response code 404, trying again...\n"
     ]
    }
   ],
   "source": [
    "def get_article_url(urls=pd.DataFrame):\n",
    "    return np.random.choice(urls.to_numpy().flatten())\n",
    "\n",
    "story_urls = nativead[['Story 1', 'Story 2', 'Story 3']]\n",
    "test_url = get_article_url(story_urls)\n",
    "article = r.get(test_url, headers)\n",
    "while not article:\n",
    "    print(test_url + ' Response code 404, trying again...')\n",
    "    try:\n",
    "        test_url = get_article_url(story_urls)\n",
    "        article = r.get(test_url, headers)\n",
    "    except r.exceptions.MissingSchema:\n",
    "        continue\n",
    "else:\n",
    "    data = article.text\n",
    "    soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop notifications are on   |Turn off\n",
      "Get breaking news alerts fromThe Washington Post\n",
      "Turn on desktop notifications?\n",
      "When it comes to the milk America drinks, cows shouldn't get all the credit. Dairy farmers like Dave and Laurie Kyle of Elkhorn, Wis., put in just as much hard work as their bovine counterparts.\n",
      "Morning for these dairy producers starts early. By 4:30, the Kyles and their farmhands are up for the first of two rounds of milking their 110 registered Holstein cows. While the cows are in the milking parlor, Dave is busy cleaning the barn, replenishing bedding and filling watering units with fresh water. Next, it's time to feed the girls a nutritious breakfast of farm-grown hay, corn and silage (a high-moisture feed that is often made from grass crops that provides many of the nutrients present in plants) mixed with soybean meal and Milwaukee malted rye. (During the warmer months, the cows also graze on fresh pasture.) Dave meets with a local nutritionist weekly, and feed blends are customized to meet each cow's current dietary needs, based on her weight and milk production level. Afternoons are more varied, yet still just as busy. In the summer, it's often the time to hop on the tractor and harvest feed crops. When the Kyles aren't harvesting, they'll often tend to other tasks, such as any variety of farm-related repairs.\n",
      "\"When you're a farmer, you have to be good at being an electrician, plumber and mechanic, because you can't really afford to pay outside vendors,\" Laurie admits.\n",
      "There's also checking in with veterinarians and testing milk for quality and safety. This includes testing for antibiotic residues — a process that takes place up to eight times before the milk is sent to the local processing plant. Setting aside time each day to simply observe the cows' behavior is also essential to ensure that they're healthy. On some days, the Kyles give farm tours, too. \"It's cool to see kids' faces light up when they pet the calves that were born a week ago, because most families don't know where their food comes from,\" says Laurie.\n",
      "While Dave spends much of his day on the farm, Laurie, a nutrition educator, can usually be found at Perkup Elkhorn, the coffee shop she opened in 2012 to forge deeper community connections and earn additional income. \"Because I'm passionate about agriculture and healthy eating, it seemed like a perfect fit. The message that I have is that American agriculture is alive and well, and farmers are still some of the most trustworthy individuals that are providing wholesome products for all,\" she says. When she isn't chatting with customers about milk's vast nutritional benefits, she's tackling bookwork for the farm in the back office.\n",
      "Dave might stop in for a bit to discuss bills, but it's back to the farm by 4:30 p.m. for the day's second round of milking, cleaning and feeding. After working as long as 17 hours, he finally arrives back home. Like most families, long days and busy schedules—including working around 16-year-old daughter Mackenzie’s travel softball games and practices and 20-year-old son Hayden’s college course load—mean the Kyles don't get to eat dinner together as often as they might like. But it's a small sacrifice to make in exchange for a truly rewarding outcome. \"Knowing you're producing wholesome products for people and doing it by rolling up your sleeves and working hard, there's a real pride involved in that,\" says Laurie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([para.get_text(strip=True) for para in soup.find_all('p')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.washingtonpost.com/?tid=tst_homelink',\n",
       " 'https://www.washingtonpost.com/elections/',\n",
       " 'https://www.washingtonpost.com/opinions/',\n",
       " 'https://www.washingtonpost.com/national/investigations/',\n",
       " 'https://www.washingtonpost.com/coronavirus/']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sponsored_div = soup.find_all('div', attrs={'class':re.compile(\"sponsor|provided\")})\n",
    "links = soup.findAll('a', attrs={'href': re.compile(\"^https*:\\/\\/\")})\n",
    "#[j.find_all('div', attrs={'class':'item'}) for j in sponsored_div if j.find_all('div', attrs={'class':'item'})!=[]]\n",
    "[j.get('href') for j in links][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_frame = pd.read_csv('data/promotional_text.csv')\n",
    "except:\n",
    "    texts = []\n",
    "    urls = nativead[['Story 1', 'Story 2', 'Story 3']].to_numpy().flatten().tolist() + promo['URLs'].to_list()\n",
    "    good_urls = []\n",
    "    more_urls = []\n",
    "    badresponses = 0\n",
    "    for i, url in enumerate(urls):\n",
    "        if url=='nan':\n",
    "            texts.append('')\n",
    "            continue\n",
    "        try:\n",
    "            article = r.get(url, headers)\n",
    "            if article:\n",
    "                good_urls.append(url)\n",
    "                links = soup.select('body p > a')\n",
    "                data = article.text\n",
    "                soup = BeautifulSoup(data)\n",
    "                article = \" \".join([para.get_text(strip=True) for para in soup.find_all('p')])\n",
    "                texts.append(article)\n",
    "            else:\n",
    "                badresponses += 1\n",
    "                texts.append('')\n",
    "        except r.exceptions.TooManyRedirects:\n",
    "            texts.append('')\n",
    "            continue\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\r\" + f\"{i!s}/{len(urls)!s} with {badresponses!s} bad responses.\")\n",
    "    sources = nativead['Site'].repeat(3).to_list() + promo['source'].to_list()\n",
    "    final_frame = pd.DataFrame({'source':sources,\n",
    "                                'url': urls,\n",
    "                                'text': texts})\n",
    "    final_frame = final_frame[final_frame['text']!='']\n",
    "    final_frame = final_frame[final_frame['text']!=' ']\n",
    "    final_frame.to_csv('data/promotional_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC News \\r\\n</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td> -- \\r\\nPresidentObamasaid today that he does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News \\r\\n</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "      <td> -- \\r\\nEven though the relatives and doctors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Network</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>“Everything that needs to be said hasalready b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>Watch live: NY Gov. Andrew Cuomo holds coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>Watch live: NY Gov. Andrew Cuomo holds coronav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                                                url  \\\n",
       "0     ABC News \\r\\n  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "1     ABC News \\r\\n  http://abcnews.go.com/Politics/justice-antonin...   \n",
       "2       CNN Network  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3  NBC News Digital  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  NBC News Digital  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "\n",
       "                                                text  \n",
       "0   -- \\r\\nPresidentObamasaid today that he does...  \n",
       "1   -- \\r\\nEven though the relatives and doctors...  \n",
       "2  “Everything that needs to be said hasalready b...  \n",
       "3  Watch live: NY Gov. Andrew Cuomo holds coronav...  \n",
       "4  Watch live: NY Gov. Andrew Cuomo holds coronav...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('promotional_news_urls.txt', mode='w') as fileout:\n",
    "    fileout.write(\"\\n\".join(final_frame.url.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assemble `ArticleVectors` straight-on, supplying one or both of the article text and the URL. This is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.1 ms ± 4.81 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = fe.ArticleVector(text='sample text', url=test_url)\n",
    "x.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 s ± 2.57 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = fe.ArticleVector(url=test_url)\n",
    "x.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full disclosure: Due to limitations in the current version of `goose3` I am unable to properly handle `ReadTimeout` exceptions, which occur when an article takes longer than expected for `requests` to receive data from. I can arbitrarily extend the timeout threshold, but this of course means that each article will take even longer to extract. Instead I opt to use the text that I scraped using `BeautifulSoup` and **omit the article title** and Goose extraction altogether.\n",
    "\n",
    "This is of no consequence in the end -- the title is only used to determine a portion of an article's `all_caps_index` and `apa_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./data/promotional_news_vectors.txt'):\n",
    "    vectors = [fe.ArticleVector(text=row['text'], url=row['url']) for _, row in final_frame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./data/promotional_news_vectors.txt'):\n",
    "    with open('data/promotional_news_vectors.txt', mode='w') as fileout:\n",
    "        fileout.write(\"\\n\".join([str(\" \".join(list(map(str, j.vector)) + ['9'])) for j in vectors]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to the NYTimes BBC Corrections dataset.\n",
    "\n",
    "I use a Powershell `cmdlet` originally obtained from [this source](http://woshub.com/powershell-get-folder-sizes/) to find those directories whose size is greater than 19.57Kb (the size of an empty Git repository). These then contain text snapshots of the first revisions of articles.\n",
    "\n",
    "```\n",
    "gci -force '.' -ErrorAction SilentlyContinue | \n",
    "    ? { ($_ -is [io.directoryinfo]) } | % {\n",
    "        $len = 0\n",
    "        gci -recurse -force $_.fullname -ErrorAction SilentlyContinue | \n",
    "           % { $len += $_.length}\n",
    "        $_.fullname, ', {0:N2}' -f ($len / 1Mb)\n",
    "} | Out-File -FilePath './nytbbcdirs.csv' -Encoding UTF8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = pd.read_csv(\"data/nytbbcdirs.csv\", encoding='utf-8', header=None, names=['dir', 'size'])\n",
    "folders['subdirs'] = [sum(1 for _ in f) for f in\n",
    "                          [os.scandir(directory) for directory in folders['dir']]]\n",
    "folders = folders[folders['size'] > 19.57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hunter\\\\dev\\\\data\\\\nytimes_bbc_2017_2020\\\\2019-01_new'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = folders.sort_values(['size', 'subdirs'], ascending=False).iloc[0]['dir']\n",
    "#path = path.replace('\\\\', '/')\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder found above is the most complete archive of the first revisions of corrected articles.\n",
    "\n",
    "We will [recursively open all bottom-level subfiles](https://stackoverflow.com/a/13617120) as text in the two URL directories. The second line is always article title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('www.bbc.co.uk\\\\news\\\\world-latin-america-47053701',\n",
       " 'www.nytimes.com\\\\2019\\\\01\\\\18\\\\opinion\\\\donald-trump-russia-putin.html',\n",
       " 'www.bbc.co.uk\\\\news\\\\world-europe-46798191',\n",
       " 'www.nytimes.com\\\\2019\\\\01\\\\07\\\\arts\\\\music\\\\21-savage-i-am-i-was-billboard-chart.html',\n",
       " 'https_\\\\www.nytimes.com\\\\2019\\\\01\\\\13\\\\realestate\\\\homes-that-sold-for-around-750000.html')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_set = set()\n",
    "for dir_, dirs, files in os.walk(path):\n",
    "    if '.git' in dirs:\n",
    "        dirs.remove('.git')\n",
    "    if '.gitignore' in files:\n",
    "        files.remove('.gitignore')\n",
    "    for file_name in files:\n",
    "        rel_dir = os.path.relpath(dir_, path)\n",
    "        rel_file = os.path.join(rel_dir, file_name)\n",
    "        file_set.add(rel_file)\n",
    "file_set = tuple(file_set); file_set[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['www.bbc.co.uk/news/world-latin-america-47053701',\n",
       " 'www.nytimes.com/2019/01/18/opinion/donald-trump-russia-putin.html',\n",
       " 'www.bbc.co.uk/news/world-europe-46798191',\n",
       " 'www.nytimes.com/2019/01/07/arts/music/21-savage-i-am-i-was-billboard-chart.html',\n",
       " 'https://www.nytimes.com/2019/01/13/realestate/homes-that-sold-for-around-750000.html']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_set = [url.replace('https_', 'https:/') for url in file_set]\n",
    "url_set = [url.replace('http_', 'http:/') for url in url_set]\n",
    "url_set = [url.replace('\\\\', '/') for url in url_set]\n",
    "url_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(url_set).to_csv('./data/corrections_urls.txt', sep=' ', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, texts = [], []\n",
    "\n",
    "for file in file_set:\n",
    "    with open(os.path.join(path, file), mode='r', encoding = 'utf-8', errors='ignore') as filein:\n",
    "        text = filein.readlines()\n",
    "        texts.append(\" \".join(text[2:]))\n",
    "        titles.append(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = pd.DataFrame({'title':titles,\n",
    "                            'text':texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\"url_ending_index\", \"from_reputable_source_index\",\n",
    "         \"today_index\", \"grammar_index\", \"quotation_index\",\n",
    "         \"past_tense_index\", \"present_tense_index\", \"should_index\",\n",
    "         \"opinion_index\", \"all_caps_index\", \"from_satire_source_index\",\n",
    "         \"exclamation_index\", \"apa_index\", \"name_source_index\",\n",
    "         \"interjection_index\", \"you_index\", \"dot_gov_ending_index\",\n",
    "         \"from_unreputable_source_index\"]\n",
    "try:\n",
    "    corrections_vectors = pd.read_csv('./data/correction_news_vectors.txt', delim_whitespace=True, header=None, names=feats)\n",
    "except FileNotFoundError:\n",
    "    corrections_vectors = []\n",
    "\n",
    "    for i, row in corrections.iterrows():\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\r\" + f\"{i!s}/{len(file_set)}\")\n",
    "        corrections_vectors.append(fe.ArticleVector(text=row['text'], title=row['title']).vector)\n",
    "\n",
    "    corrections_vectors = pd.DataFrame(corrections_vectors, columns=feats)\n",
    "    corrections_vectors = corrections_vectors.assign(url_ending_index=1)\n",
    "    corrections_vectors = corrections_vectors.assign(dot_gov_ending_index=0)\n",
    "    corrections_vectors = corrections_vectors.assign(label=11)\n",
    "\n",
    "    corrections_vectors.to_csv('./data/correction_news_vectors.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6805, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Native Ads:</th>\n",
       "      <th>Press Release:</th>\n",
       "      <th>False news</th>\n",
       "      <th>Real news</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Satire</th>\n",
       "      <th>Misreporting</th>\n",
       "      <th>Polarized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.businessinsider.com/sc/how-to-crea...</td>\n",
       "      <td>https://sports.yahoo.com/mango-non-medical-clo...</td>\n",
       "      <td>https://web.archive.org/web/20200601103700/htt...</td>\n",
       "      <td>https://www.cnn.com/2020/05/12/health/us-coron...</td>\n",
       "      <td>https://www.cnn.com/2020/06/12/opinions/corona...</td>\n",
       "      <td>https://babylonbee.com/news/pelosi-rips-up-bible</td>\n",
       "      <td>https://www.nytimes.com/2020/06/08/world/middl...</td>\n",
       "      <td>https://www.nationalreview.com/2020/06/trump-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.inc.com/verizon/the-new-security-c...</td>\n",
       "      <td>https://www.automotiveworld.com/news-releases/...</td>\n",
       "      <td>https://web.archive.org/web/20200430182051/htt...</td>\n",
       "      <td>https://apnews.com/f18aadd2d6a2868c3765a02c2c9...</td>\n",
       "      <td>https://www.cnn.com/2020/06/11/opinions/time-p...</td>\n",
       "      <td>https://worldnewsdailyreport.com/florida-teen-...</td>\n",
       "      <td>https://www.reuters.com/article/us-health-coro...</td>\n",
       "      <td>https://dailycaller.com/2020/06/19/tucker-carl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://nationalpost.com/sponsored/food-drink-...</td>\n",
       "      <td>https://thedcline.org/2020/06/11/press-release...</td>\n",
       "      <td>https://web.archive.org/web/20200424225130/htt...</td>\n",
       "      <td>https://www.nytimes.com/2020/05/29/technology/...</td>\n",
       "      <td>https://www.theguardian.com/commentisfree/2019...</td>\n",
       "      <td>https://www.duffelblog.com/2014/12/army-milita...</td>\n",
       "      <td>https://apnews.com/eac82d6b410648ae8cccfb54f91...</td>\n",
       "      <td>https://www.breitbart.com/social-justice/2020/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.forbes.com/sites/qatarfoundation/2...</td>\n",
       "      <td>https://www.prnewswire.com/news-releases/money...</td>\n",
       "      <td>https://archive.is/uGHEb</td>\n",
       "      <td>https://www.bbc.com/news/world-us-canada-52557291</td>\n",
       "      <td>https://www.theguardian.com/commentisfree/2020...</td>\n",
       "      <td>https://web.archive.org/web/20200630111931/htt...</td>\n",
       "      <td>https://www.foxnews.com/us/correction-hot-air-...</td>\n",
       "      <td>https://www.thedailybeast.com/local-businesses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thisisreno.com/2020/06/remsa-partners-...</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>http://archive.vn/8Kp0r#selection-427.1-427.40</td>\n",
       "      <td>https://popular.info/p/amazon-soliciting-publi...</td>\n",
       "      <td>https://www.usatoday.com/story/opinion/2020/06...</td>\n",
       "      <td>https://www.gishgallop.com/area-skydiver-caugh...</td>\n",
       "      <td>https://spectator.org/not-at-home-again-in-ind...</td>\n",
       "      <td>https://slate.com/news-and-politics/2020/06/wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Native Ads:  \\\n",
       "0  https://www.businessinsider.com/sc/how-to-crea...   \n",
       "1  https://www.inc.com/verizon/the-new-security-c...   \n",
       "2  https://nationalpost.com/sponsored/food-drink-...   \n",
       "3  https://www.forbes.com/sites/qatarfoundation/2...   \n",
       "4  https://thisisreno.com/2020/06/remsa-partners-...   \n",
       "\n",
       "                                      Press Release:  \\\n",
       "0  https://sports.yahoo.com/mango-non-medical-clo...   \n",
       "1  https://www.automotiveworld.com/news-releases/...   \n",
       "2  https://thedcline.org/2020/06/11/press-release...   \n",
       "3  https://www.prnewswire.com/news-releases/money...   \n",
       "4  https://www.globenewswire.com/news-release/202...   \n",
       "\n",
       "                                          False news  \\\n",
       "0  https://web.archive.org/web/20200601103700/htt...   \n",
       "1  https://web.archive.org/web/20200430182051/htt...   \n",
       "2  https://web.archive.org/web/20200424225130/htt...   \n",
       "3                           https://archive.is/uGHEb   \n",
       "4     http://archive.vn/8Kp0r#selection-427.1-427.40   \n",
       "\n",
       "                                           Real news  \\\n",
       "0  https://www.cnn.com/2020/05/12/health/us-coron...   \n",
       "1  https://apnews.com/f18aadd2d6a2868c3765a02c2c9...   \n",
       "2  https://www.nytimes.com/2020/05/29/technology/...   \n",
       "3  https://www.bbc.com/news/world-us-canada-52557291   \n",
       "4  https://popular.info/p/amazon-soliciting-publi...   \n",
       "\n",
       "                                             Opinion  \\\n",
       "0  https://www.cnn.com/2020/06/12/opinions/corona...   \n",
       "1  https://www.cnn.com/2020/06/11/opinions/time-p...   \n",
       "2  https://www.theguardian.com/commentisfree/2019...   \n",
       "3  https://www.theguardian.com/commentisfree/2020...   \n",
       "4  https://www.usatoday.com/story/opinion/2020/06...   \n",
       "\n",
       "                                              Satire  \\\n",
       "0   https://babylonbee.com/news/pelosi-rips-up-bible   \n",
       "1  https://worldnewsdailyreport.com/florida-teen-...   \n",
       "2  https://www.duffelblog.com/2014/12/army-milita...   \n",
       "3  https://web.archive.org/web/20200630111931/htt...   \n",
       "4  https://www.gishgallop.com/area-skydiver-caugh...   \n",
       "\n",
       "                                        Misreporting  \\\n",
       "0  https://www.nytimes.com/2020/06/08/world/middl...   \n",
       "1  https://www.reuters.com/article/us-health-coro...   \n",
       "2  https://apnews.com/eac82d6b410648ae8cccfb54f91...   \n",
       "3  https://www.foxnews.com/us/correction-hot-air-...   \n",
       "4  https://spectator.org/not-at-home-again-in-ind...   \n",
       "\n",
       "                                           Polarized  \n",
       "0  https://www.nationalreview.com/2020/06/trump-a...  \n",
       "1  https://dailycaller.com/2020/06/19/tucker-carl...  \n",
       "2  https://www.breitbart.com/social-justice/2020/...  \n",
       "3  https://www.thedailybeast.com/local-businesses...  \n",
       "4  https://slate.com/news-and-politics/2020/06/wa...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test = pd.read_csv('./data/human_test_articles.csv')\n",
    "d_test = d_test.drop('Citizen Journalism', axis=1)\n",
    "d_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test_final = dict(real=d_test['Real news'].dropna(),\n",
    "                    fake=d_test['False news'].dropna(),\n",
    "                    opinion=d_test['Opinion'].dropna(),\n",
    "                    polarized=d_test['Polarized'].dropna(),\n",
    "                    satire=d_test['Satire'].dropna(),\n",
    "                    promotional=pd.concat([d_test['Native Ads:'], d_test['Press Release:']]).dropna().reset_index(drop=True),\n",
    "                    correction=d_test['Misreporting'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_set_vectors = {}\n",
    "for label, url_series in d_test_final.items():\n",
    "        human_set_vectors[label] = url_series.apply(lambda j: fe.ArticleVector(url=j).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_labeled = []\n",
    "for label, vec_series in human_set_vectors.items():\n",
    "    for vector in vec_series:\n",
    "        vectors_labeled.append(vector + [CLASS_DICT[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_ending_index</th>\n",
       "      <th>from_reputable_source_index</th>\n",
       "      <th>today_index</th>\n",
       "      <th>grammar_index</th>\n",
       "      <th>quotation_index</th>\n",
       "      <th>past_tense_index</th>\n",
       "      <th>present_tense_index</th>\n",
       "      <th>should_index</th>\n",
       "      <th>opinion_index</th>\n",
       "      <th>all_caps_index</th>\n",
       "      <th>from_satire_source_index</th>\n",
       "      <th>exclamation_index</th>\n",
       "      <th>apa_index</th>\n",
       "      <th>name_source_index</th>\n",
       "      <th>interjection_index</th>\n",
       "      <th>you_index</th>\n",
       "      <th>dot_gov_ending_index</th>\n",
       "      <th>from_unreputable_source_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.080160</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095775</td>\n",
       "      <td>0.076056</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034568</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.093827</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.072008</td>\n",
       "      <td>0.081136</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_ending_index  from_reputable_source_index  today_index  grammar_index  \\\n",
       "0                 1                            0     0.000000       0.050505   \n",
       "1                 1                            0     0.000000       0.030060   \n",
       "2                 1                            0     0.002817       0.014085   \n",
       "3                 1                            0     0.000000       0.034568   \n",
       "4                 0                            0     0.000000       0.044625   \n",
       "\n",
       "   quotation_index  past_tense_index  present_tense_index  should_index  \\\n",
       "0         0.040404          0.053030             0.136364      0.000000   \n",
       "1         0.004008          0.080160             0.048096      0.004008   \n",
       "2         0.000000          0.095775             0.076056      0.005634   \n",
       "3         0.009877          0.093827             0.074074      0.000000   \n",
       "4         0.022312          0.072008             0.081136      0.002028   \n",
       "\n",
       "   opinion_index  all_caps_index  from_satire_source_index  exclamation_index  \\\n",
       "0              0        0.020202                         1                0.0   \n",
       "1              0        0.018036                         1                0.0   \n",
       "2              0        0.000000                         1                0.0   \n",
       "3              0        0.051852                         1                0.0   \n",
       "4              0        0.015213                         1                0.0   \n",
       "\n",
       "   apa_index  name_source_index  interjection_index  you_index  \\\n",
       "0          1           0.073232                 0.0   0.000000   \n",
       "1          0           0.246493                 0.0   0.000000   \n",
       "2          0           0.157746                 0.0   0.000000   \n",
       "3          0           0.167901                 0.0   0.000000   \n",
       "4          1           0.091278                 0.0   0.001014   \n",
       "\n",
       "   dot_gov_ending_index  from_unreputable_source_index  label  \n",
       "0                     0                              0      1  \n",
       "1                     0                              0      1  \n",
       "2                     0                              0      1  \n",
       "3                     0                              0      1  \n",
       "4                     0                              0      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_human = pd.DataFrame(vectors_labeled, columns=feats+['label'])\n",
    "d_human.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d_human['url_ending_index'] = [1.0 if ending in ('com', 'org', 'gov') else 0.0 for ending in [tldextract.extract(url).suffix for url in pd.concat(d_test_final.values())]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d_human['dot_gov_ending_index'] = [1.0 if ending=='gov' else 0.0 for ending in [tldextract.extract(url).suffix for url in pd.concat(d_test_final.values())]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_human.to_csv('./data/human_test_vectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
