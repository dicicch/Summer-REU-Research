{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import requests as r\n",
    "import itertools as it\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.chdir('../')\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = r.utils.default_headers()\n",
    "headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Status</th>\n",
       "      <th>Coder</th>\n",
       "      <th>Story 1</th>\n",
       "      <th>Story 2</th>\n",
       "      <th>Story 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo News</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DI</td>\n",
       "      <td>https://goingthere.yahoo.com/post/133803688011...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130087715036...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130160620511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>Done</td>\n",
       "      <td>DI</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/providence-...</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CNN Network</td>\n",
       "      <td>DONE</td>\n",
       "      <td>BWW</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/amazon/article/8...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/subaru/article/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>DONE</td>\n",
       "      <td>NJE</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>http://www.nbcnews.com/video/he-creates-furnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HuffingtonPost.com</td>\n",
       "      <td>DONE</td>\n",
       "      <td>BWW</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/06/04/best-...</td>\n",
       "      <td>http://www.huffingtonpost.com/kathy-magee/a-sm...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/05/29/evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site Status Coder  \\\n",
       "0          Yahoo News   DONE    DI   \n",
       "1         ABC News \\n   Done    DI   \n",
       "2         CNN Network   DONE   BWW   \n",
       "3    NBC News Digital   DONE   NJE   \n",
       "4  HuffingtonPost.com   DONE   BWW   \n",
       "\n",
       "                                             Story 1  \\\n",
       "0  https://goingthere.yahoo.com/post/133803688011...   \n",
       "1  http://abcnews.go.com/US/wireStory/providence-...   \n",
       "2  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  http://www.huffingtonpost.com/2015/06/04/best-...   \n",
       "\n",
       "                                             Story 2  \\\n",
       "0  https://goingthere.yahoo.com/post/130087715036...   \n",
       "1  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "2  http://sponsorcontent.cnn.com/amazon/article/8...   \n",
       "3  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "4  http://www.huffingtonpost.com/kathy-magee/a-sm...   \n",
       "\n",
       "                                             Story 3  \n",
       "0  https://goingthere.yahoo.com/post/130160620511...  \n",
       "1  http://abcnews.go.com/Politics/justice-antonin...  \n",
       "2  http://sponsorcontent.cnn.com/subaru/article/a...  \n",
       "3  http://www.nbcnews.com/video/he-creates-furnit...  \n",
       "4  http://www.huffingtonpost.com/2015/05/29/evolu...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = pd.read_excel(\"data/Nativead.xlsx\")\n",
    "nativead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/release-of-the-united-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/conclusion-of-negotiatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/u-s-mexico-joint-declara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/united-states-restricts-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/president-donald-j-trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source                                               URLs\n",
       "0  U.S. Department of State  https://www.state.gov/release-of-the-united-st...\n",
       "1  U.S. Department of State  https://www.state.gov/conclusion-of-negotiatio...\n",
       "2  U.S. Department of State  https://www.state.gov/u-s-mexico-joint-declara...\n",
       "3  U.S. Department of State  https://www.state.gov/united-states-restricts-...\n",
       "4  U.S. Department of State  https://www.state.gov/president-donald-j-trump..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo = pd.read_excel(\"data/PR_content_news.xlsx\")\n",
    "promo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DONE                38\n",
       "Done                 5\n",
       "N/A, now defunct     1\n",
       "Found only 1         1\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site       0\n",
       "Status     0\n",
       "Coder      0\n",
       "Story 1    0\n",
       "Story 2    0\n",
       "Story 3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = nativead.astype(str)\n",
    "nativead = nativead[nativead['Status'].apply(str.lower)=='done']\n",
    "nativead.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Story 1</th>\n",
       "      <th>Story 2</th>\n",
       "      <th>Story 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo News</td>\n",
       "      <td>https://goingthere.yahoo.com/post/133803688011...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130087715036...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130160620511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/providence-...</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CNN Network</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/amazon/article/8...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/subaru/article/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>http://www.nbcnews.com/video/he-creates-furnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HuffingtonPost.com</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/06/04/best-...</td>\n",
       "      <td>http://www.huffingtonpost.com/kathy-magee/a-sm...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/05/29/evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site                                            Story 1  \\\n",
       "0          Yahoo News  https://goingthere.yahoo.com/post/133803688011...   \n",
       "1         ABC News \\n  http://abcnews.go.com/US/wireStory/providence-...   \n",
       "2         CNN Network  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3    NBC News Digital  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  HuffingtonPost.com  http://www.huffingtonpost.com/2015/06/04/best-...   \n",
       "\n",
       "                                             Story 2  \\\n",
       "0  https://goingthere.yahoo.com/post/130087715036...   \n",
       "1  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "2  http://sponsorcontent.cnn.com/amazon/article/8...   \n",
       "3  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "4  http://www.huffingtonpost.com/kathy-magee/a-sm...   \n",
       "\n",
       "                                             Story 3  \n",
       "0  https://goingthere.yahoo.com/post/130160620511...  \n",
       "1  http://abcnews.go.com/Politics/justice-antonin...  \n",
       "2  http://sponsorcontent.cnn.com/subaru/article/a...  \n",
       "3  http://www.nbcnews.com/video/he-creates-furnit...  \n",
       "4  http://www.huffingtonpost.com/2015/05/29/evolu...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = nativead.drop(['Status', 'Coder'], axis=1)\n",
    "nativead.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_url(urls=pd.DataFrame):\n",
    "    return np.random.choice(urls.to_numpy().flatten())\n",
    "\n",
    "story_urls = nativead[['Story 1', 'Story 2', 'Story 3']]\n",
    "test_url = get_article_url(story_urls)\n",
    "article = r.get(test_url, headers)\n",
    "while not article:\n",
    "    print(test_url + ' Response code 404, trying again...')\n",
    "    try:\n",
    "        test_url = get_article_url(story_urls)\n",
    "        article = r.get(test_url, headers)\n",
    "    except r.exceptions.MissingSchema:\n",
    "        continue\n",
    "else:\n",
    "    data = article.text\n",
    "    soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iStockIn the world of modern business, where you are is just as important as what you do. The right location plays a big part in attracting qualified talent, allowing more collaboration, and presenting a relatable, physical association for customers and clients.Today, real estate is not necessarily seen as a source of competitive advantage – but it very much is.It's actually a tool that can drive business.\n",
      "Skilled real estate management is a discipline; lack of experience can have serious consequences. Both new and established companies are susceptible to bad real estate decisions without realizing the implications they can have on the business — or the value a good real estate move can offer. Here's how one company has used real estate as a successful business strategy.\n",
      "Young & Rubicam is one of the most recognized and respected ad agencies in the world. But a few years ago Y&R was going through changes.For more than 86 years, the agency’s global headquarters were at 285 Madison Avenue in New York City, and the space was synonymous with the agency itself. However, as Y&R continued to expand, its space on Madison avenue no longer provided the amenities it needed. Finding the right space was critical for Y&R; not only did it have to meet its expanding needs, it also had to be a space where the agency's culture, ethos, and creativity could thrive.\n",
      "Working withCBRE, a commercial real estate services firm, Y&Ridentified 3 Columbus Circle as the ideal site for its new global headquarters. CBRE helped Y&R secure ahybrid deal to acquire a condominium interest of floors three through eight, and enter into a 20-year lease for floors nine, 10, 18, and 19 at 3 Columbus Circle.\n",
      "Y&R's new offices allow for creative expression and better collaboration.CBREOne of the many draws of the new building is that it provides a number of features that are appealing to both employees and clients, including a sunlit mix of public and private space. Different pieces of art on the walls match the creativity of the campaigns that come from the agency teams. Recognizing that the office is where many employees spend most of their time, Y&R created a number of break areas: a roof deck where people can enjoy stunning views of Central Park; a cafeteria that offers a number of different dining options; and areas for employees to relax and even play foosball and shuffleboard.\n",
      "And it's not just the actual building that can influence employees' happiness — the location is also a big draw. The neighborhood has easy subway access, so it's convenient for employees from across the numerous New York City boroughs. Because the office is part of a hub that houses other agencies within WPP (Y&R's holding company), it creates a great space for Y&R to collaborate with colleagues at sister firms.\n",
      "The space has proven to be a valuable asset for Y&R, helping the firm deliver on its best-in-class creative reputation and serve as a place where both employees and clients want to be. Another reminder that it’s not just about what you do, but where you do it.\n",
      "Find out more about Y&R’s story and how the right real estate can help your business.\n",
      "This post is sponsored byCBRE.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([para.get_text(strip=True) for para in soup.find_all('p')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://intelligence.businessinsider.com/account',\n",
       " 'https://www.insider.com/lifestyle',\n",
       " 'https://www.insider.com/news',\n",
       " 'https://insider.com',\n",
       " 'https://www.insider.com/lifestyle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sponsored_div = soup.find_all('div', attrs={'class':re.compile(\"sponsor|provided\")})\n",
    "links = soup.findAll('a', attrs={'href': re.compile(\"^https*:\\/\\/\")})\n",
    "#[j.find_all('div', attrs={'class':'item'}) for j in sponsored_div if j.find_all('div', attrs={'class':'item'})!=[]]\n",
    "[j.get('href') for j in links][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_frame = pd.read_csv('data/promotional_text.csv')\n",
    "except:\n",
    "    texts = []\n",
    "    urls = nativead[['Story 1', 'Story 2', 'Story 3']].to_numpy().flatten().tolist() + promo['URLs'].to_list()\n",
    "    good_urls = []\n",
    "    more_urls = []\n",
    "    badresponses = 0\n",
    "    for i, url in enumerate(urls):\n",
    "        if url=='nan':\n",
    "            texts.append('')\n",
    "            continue\n",
    "        try:\n",
    "            article = r.get(url, headers)\n",
    "            if article:\n",
    "                good_urls.append(url)\n",
    "                links = soup.select('body p > a')\n",
    "                data = article.text\n",
    "                soup = BeautifulSoup(data)\n",
    "                article = \" \".join([para.get_text(strip=True) for para in soup.find_all('p')])\n",
    "                texts.append(article)\n",
    "            else:\n",
    "                badresponses += 1\n",
    "                texts.append('')\n",
    "        except r.exceptions.TooManyRedirects:\n",
    "            texts.append('')\n",
    "            continue\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\r\" + f\"{i!s}/{len(urls)!s} with {badresponses!s} bad responses.\")\n",
    "    sources = nativead['Site'].repeat(3).to_list() + promo['source'].to_list()\n",
    "    final_frame = pd.DataFrame({'source':sources,\n",
    "                                'url': urls,\n",
    "                                'text': texts})\n",
    "    final_frame = final_frame[final_frame['text']!='']\n",
    "    final_frame = final_frame[final_frame['text']!=' ']\n",
    "    final_frame.to_csv('data/promotional_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td> -- \\nPresidentObamasaid today that he does n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "      <td> -- \\nEven though the relatives and doctors o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CNN Network</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>“Everything that needs to be said hasalready b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>Watch live: NY Gov. Andrew Cuomo holds coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>Watch live: NY Gov. Andrew Cuomo holds coronav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                                                url  \\\n",
       "0       ABC News \\n  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "1       ABC News \\n  http://abcnews.go.com/Politics/justice-antonin...   \n",
       "2       CNN Network  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3  NBC News Digital  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  NBC News Digital  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "\n",
       "                                                text  \n",
       "0   -- \\nPresidentObamasaid today that he does n...  \n",
       "1   -- \\nEven though the relatives and doctors o...  \n",
       "2  “Everything that needs to be said hasalready b...  \n",
       "3  Watch live: NY Gov. Andrew Cuomo holds coronav...  \n",
       "4  Watch live: NY Gov. Andrew Cuomo holds coronav...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('promotional_news_urls.txt', mode='w') as fileout:\n",
    "    fileout.write(\"\\n\".join(final_frame.url.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assemble `ArticleVectors` straight-on, supplying one or both of the article text and the URL. This is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.8 ms ± 4.89 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = fe.ArticleVector(text='sample text', url=test_url)\n",
    "x.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509 ms ± 29.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = fe.ArticleVector(url=test_url)\n",
    "x.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full disclosure: Due to limitations in the current version of `goose3` I am unable to properly handle `ReadTimeout` exceptions, which occur when an article takes longer than expected for `requests` to receive data from. I can arbitrarily extend the timeout threshold, but this of course means that each article will take even longer to extract. Instead I opt to use the text that I scraped using `BeautifulSoup` and **omit the article title** and Goose extraction altogether.\n",
    "\n",
    "This is of no consequence in the end -- the title is only used to determine a portion of an article's `all_caps_index` and `apa_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [fe.ArticleVector(text=row['text'], url=row['url']) for _, row in final_frame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/promotional_news_vectors.txt', mode='w') as fileout:\n",
    "    fileout.write(\"\\n\")\n",
    "    fileout.write(\"\\n\".join([str(\" \".join(list(map(str, j.vector)))) for j in vectors]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to the NYTimes BBC Corrections dataset.\n",
    "\n",
    "I use a Powershell `cmdlet` from [this source](http://woshub.com/powershell-get-folder-sizes/) to find those directories whose size is greater than 19.57Kb (the size of an empty Git repository). These then contain text snapshots of the first revisions of articles.\n",
    "\n",
    "```\n",
    "gci -force '.' -ErrorAction SilentlyContinue | \n",
    "    ? { ($_ -is [io.directoryinfo]) } | % {\n",
    "        $len = 0\n",
    "        gci -recurse -force $_.fullname -ErrorAction SilentlyContinue | \n",
    "           % { $len += $_.length}\n",
    "        $_.fullname, ', {0:N2}' -f ($len / 1Mb)\n",
    "} | Out-File -FilePath './nytbbcdirs.csv' -Encoding UTF8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = pd.read_csv(\"data/nytbbcdirs.csv\", encoding='utf-8', header=None, names=['dir', 'size'])\n",
    "folders = folders[folders['size'] > 19.57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hunter\\\\dev\\\\data\\\\nytimes_bbc_2017_2020\\\\2019-05_new'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = folders.max()['dir'].rstrip(\" \"); path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder found above is the most complete archive of the first revisions of corrected articles.\n",
    "\n",
    "We will [recursively open all bottom-level subfiles](https://stackoverflow.com/a/13617120) as text in the two URL directories. The second line is always article title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https_\\\\www.nytimes.com\\\\2019\\\\04\\\\30\\\\realestate\\\\commercial\\\\new-york-commercial-real-estate.html',\n",
       " 'www.bbc.co.uk\\\\news\\\\world-asia-48169104',\n",
       " 'https_\\\\www.nytimes.com\\\\2019\\\\05\\\\02\\\\arts\\\\design\\\\frieze-new-york-review-art-fair.html',\n",
       " 'www.bbc.co.uk\\\\news\\\\uk-48459760',\n",
       " 'www.bbc.co.uk\\\\news\\\\world-asia-48222627')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_set = set()\n",
    "for dir_, dirs, files in os.walk(path):\n",
    "    if '.git' in dirs:\n",
    "        dirs.remove('.git')\n",
    "    if '.gitignore' in files:\n",
    "        files.remove('.gitignore')\n",
    "    for file_name in files:\n",
    "        rel_dir = os.path.relpath(dir_, path)\n",
    "        rel_file = os.path.join(rel_dir, file_name)\n",
    "        file_set.add(rel_file)\n",
    "file_set = tuple(file_set); file_set[0:5]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, texts = [], []\n",
    "\n",
    "for file in file_set:\n",
    "    with open(os.path.join(path, file), mode='r', encoding = 'utf-8', errors='ignore') as filein:\n",
    "        text = filein.readlines()\n",
    "        texts.append(\" \".join(text[2:]))\n",
    "        titles.append(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = pd.DataFrame({'title':titles,\n",
    "                            'text':texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4642/4643"
     ]
    }
   ],
   "source": [
    "#corrections_vectors = [fe.ArticleVector(text=row['text'], title=row['title']) for _, row in corrections.iterrows()]\n",
    "corrections_vectors = []\n",
    "for i, row in corrections.iterrows():\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write(\"\\r\" + f\"{i!s}/{len(file_set)}\")\n",
    "    corrections_vectors.append(fe.ArticleVector(text=row['text'], title=row['title']).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/corrections_news_vectors.txt', mode='w') as fileout:\n",
    "    fileout.write(\"\\n\")\n",
    "    fileout.write(\"\\n\".join([str(\" \".join(list(map(str, j)))) for j in corrections_vectors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
