{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hunter S. DiCicco\n",
    "\n",
    "with Dr. Dongwon Lee, Ph.D.\n",
    "\n",
    "# Data Collection: Limited Web Scraping\n",
    "for *Promotional* and *Misreporting* Content\n",
    "\n",
    "## TODO:\n",
    "* Rectify Promotional Content/Native Ads Class Balance\n",
    "\n",
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import requests as r\n",
    "import itertools as it\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "os.chdir('../')\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = r.utils.default_headers()\n",
    "headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Status</th>\n",
       "      <th>Coder</th>\n",
       "      <th>Story 1</th>\n",
       "      <th>Story 2</th>\n",
       "      <th>Story 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yahoo News</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DI</td>\n",
       "      <td>https://goingthere.yahoo.com/post/133803688011...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130087715036...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130160620511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>Done</td>\n",
       "      <td>DI</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/providence-...</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Network</td>\n",
       "      <td>DONE</td>\n",
       "      <td>BWW</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/amazon/article/8...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/subaru/article/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>DONE</td>\n",
       "      <td>NJE</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>http://www.nbcnews.com/video/he-creates-furnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuffingtonPost.com</td>\n",
       "      <td>DONE</td>\n",
       "      <td>BWW</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/06/04/best-...</td>\n",
       "      <td>http://www.huffingtonpost.com/kathy-magee/a-sm...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/05/29/evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site Status Coder  \\\n",
       "0          Yahoo News   DONE    DI   \n",
       "1         ABC News \\n   Done    DI   \n",
       "2         CNN Network   DONE   BWW   \n",
       "3    NBC News Digital   DONE   NJE   \n",
       "4  HuffingtonPost.com   DONE   BWW   \n",
       "\n",
       "                                             Story 1  \\\n",
       "0  https://goingthere.yahoo.com/post/133803688011...   \n",
       "1  http://abcnews.go.com/US/wireStory/providence-...   \n",
       "2  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  http://www.huffingtonpost.com/2015/06/04/best-...   \n",
       "\n",
       "                                             Story 2  \\\n",
       "0  https://goingthere.yahoo.com/post/130087715036...   \n",
       "1  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "2  http://sponsorcontent.cnn.com/amazon/article/8...   \n",
       "3  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "4  http://www.huffingtonpost.com/kathy-magee/a-sm...   \n",
       "\n",
       "                                             Story 3  \n",
       "0  https://goingthere.yahoo.com/post/130160620511...  \n",
       "1  http://abcnews.go.com/Politics/justice-antonin...  \n",
       "2  http://sponsorcontent.cnn.com/subaru/article/a...  \n",
       "3  http://www.nbcnews.com/video/he-creates-furnit...  \n",
       "4  http://www.huffingtonpost.com/2015/05/29/evolu...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = pd.read_excel(\"data/Nativead.xlsx\")\n",
    "nativead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/release-of-the-united-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/conclusion-of-negotiatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/u-s-mexico-joint-declara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/united-states-restricts-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S. Department of State</td>\n",
       "      <td>https://www.state.gov/president-donald-j-trump...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source                                               URLs\n",
       "0  U.S. Department of State  https://www.state.gov/release-of-the-united-st...\n",
       "1  U.S. Department of State  https://www.state.gov/conclusion-of-negotiatio...\n",
       "2  U.S. Department of State  https://www.state.gov/u-s-mexico-joint-declara...\n",
       "3  U.S. Department of State  https://www.state.gov/united-states-restricts-...\n",
       "4  U.S. Department of State  https://www.state.gov/president-donald-j-trump..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo = pd.read_excel(\"data/PR_content_news.xlsx\")\n",
    "promo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DONE                38\n",
       "Done                 5\n",
       "N/A, now defunct     1\n",
       "Found only 1         1\n",
       "Name: Status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead['Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site       0\n",
       "Status     0\n",
       "Coder      0\n",
       "Story 1    0\n",
       "Story 2    0\n",
       "Story 3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = nativead.astype(str)\n",
    "nativead = nativead[nativead['Status'].apply(str.lower)=='done']\n",
    "nativead.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Story 1</th>\n",
       "      <th>Story 2</th>\n",
       "      <th>Story 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yahoo News</td>\n",
       "      <td>https://goingthere.yahoo.com/post/133803688011...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130087715036...</td>\n",
       "      <td>https://goingthere.yahoo.com/post/130160620511...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News \\n</td>\n",
       "      <td>http://abcnews.go.com/US/wireStory/providence-...</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Network</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/amazon/article/8...</td>\n",
       "      <td>http://sponsorcontent.cnn.com/subaru/article/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>http://www.nbcnews.com/video/he-creates-furnit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HuffingtonPost.com</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/06/04/best-...</td>\n",
       "      <td>http://www.huffingtonpost.com/kathy-magee/a-sm...</td>\n",
       "      <td>http://www.huffingtonpost.com/2015/05/29/evolu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site                                            Story 1  \\\n",
       "0          Yahoo News  https://goingthere.yahoo.com/post/133803688011...   \n",
       "1         ABC News \\n  http://abcnews.go.com/US/wireStory/providence-...   \n",
       "2         CNN Network  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3    NBC News Digital  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  HuffingtonPost.com  http://www.huffingtonpost.com/2015/06/04/best-...   \n",
       "\n",
       "                                             Story 2  \\\n",
       "0  https://goingthere.yahoo.com/post/130087715036...   \n",
       "1  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "2  http://sponsorcontent.cnn.com/amazon/article/8...   \n",
       "3  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "4  http://www.huffingtonpost.com/kathy-magee/a-sm...   \n",
       "\n",
       "                                             Story 3  \n",
       "0  https://goingthere.yahoo.com/post/130160620511...  \n",
       "1  http://abcnews.go.com/Politics/justice-antonin...  \n",
       "2  http://sponsorcontent.cnn.com/subaru/article/a...  \n",
       "3  http://www.nbcnews.com/video/he-creates-furnit...  \n",
       "4  http://www.huffingtonpost.com/2015/05/29/evolu...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nativead = nativead.drop(['Status', 'Coder'], axis=1)\n",
    "nativead.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_url(urls=pd.DataFrame):\n",
    "    return np.random.choice(urls.to_numpy().flatten())\n",
    "\n",
    "story_urls = nativead[['Story 1', 'Story 2', 'Story 3']]\n",
    "test_url = get_article_url(story_urls)\n",
    "article = r.get(test_url, headers)\n",
    "while not article:\n",
    "    print(test_url + ' Response code 404, trying again...')\n",
    "    try:\n",
    "        test_url = get_article_url(story_urls)\n",
    "        article = r.get(test_url, headers)\n",
    "    except r.exceptions.MissingSchema:\n",
    "        continue\n",
    "else:\n",
    "    data = article.text\n",
    "    soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Partnered content\n",
      "Presented by Mazda\n",
      "This is the first article in a four-part special advertising feature series presented by Mazda that looks at the ongoing relationship between technology, innovation and sport.\n",
      "Technical innovation in sport - it's something we as participants and fans take for granted now. It could be Grand Prix champion Lewis Hamilton talking to his pit crew throughout his thrilling drive in Austin Texas to win the 2015 Formula One title. Or improvements in the safety standards of cricketers' helmets, following the death of Australian Test batsman Phillip Hughes when a delivery struck him at the top of his neck, in Sydney in 2014.\n",
      "Perhaps the most interesting development is the introduction of ingestible computers that constantly transmit data on a player's vital functions, such as blood pressure and body temperature. Athletes in sports as diverse as motor sport, athletics, football and hockey are already using them. It's the latest innovation in the ever-changing world of sports technology.\n",
      "If you look at the many incredible achievements of the modern world, chances are you'll find it's a result of a potent combination of innovation and technology.\n",
      "This combination lets us live and move like never before.\n",
      "Mazda's innovation and technology has allowed them to develop the Mazda CX-3.\n",
      "Let's turn the clock back more than 70 years, when one of sport's greatest innovations evolved from a bitter feud between two brothers.  Adi and Rudi Dassler were partners in a sports shoe company in Herzogenaurach, Germany. After  an acrimonious split , the brothers formed rival companies - Adidas and Puma - on opposite sides of the river Aurach.\n",
      "The schism inspired a battle for domination in athletic footwear - firstly in newly formed West Germany, and then the rest of the world. It led to a race to find styles and materials that gave top athletes the slightest advantage. Manufacturers  are still in a fight for domination, with the global market tipped to be worth US$84.4 billion in 2018. Amazingly, Adidas and Puma are still up there fighting for their share of the lucrative sports shoe market, along with Nike, Reebok and other companies.\n",
      "The only objective is to win - to be bigger, stronger, faster … smarter.\n",
      "Athletes, teams and sports organisations will always seek to find an edge over their rivals (or the stopwatch). It might be the chance to gain a physical advantage through better training techniques, or a mental edge through superior tactics. Or it might be through playing with equipment that allows them to go faster, with more comfort and safety, for longer. At the 2015 Tour de France, for example, cyclists carried miniature GPS-equipped computers that tracked speed, distance travelled and calories burned.\n",
      "Technology continues to be crucial factor in any individual or team success, especially at the elite level. And as every player or team finds an advantage, opponents try to counter it. This sports innovation cycle  has made billionaires of entrepreneurs in the sports equipment industry, and created jobs for sports scientists and psychologists who deliver stunning results for athletes, teams and sponsors.\n",
      "The push for sporting innovation has also given spectators the chance to be more involved in the action.  Using miniature, high-speed and even infrared cameras and ultra-sensitive microphones, broadcasters and sports organisations bring fans closer to the action. Intimacy equals greater ratings and sponsorship money.\n",
      "When Tennis legend John McEnroe screamed 'You Cannot Be Serious' at the Umpire while contesting a decision, it added to the excitement for the Wimbledon crowd. With the introduction of Hawk-Eye in Grand Slams in 2006, we may have lost some of the human drama, but we've gained a near-faultless ball-tracking technology that enjoys the support  of most players and officials. Many sporting organisations,  including  the NFL in the US, and the Rugby Union authorities at the recent World Cup in England, use \"slo-mo\" video technology as part of their on-field decision-making, while their officials  use it to determine if players should be suspended for foul play.\n",
      "Technology has also had  a fundamental impact on the way players train. Cutting-edge training facilities are a home away from home for elite athletes, who rely on sophisticated machines and monitors to reach peak performance while averting the risk of injury. Sports scientists use technology to develop training regimes that allow individual athletes to perform at their best.\n",
      "Modern technology also allows sports to find future stars, with talented teenagers tested to determine which disciplines best suit their physiology. These days, star rowers are discovered before they even step onto a boat. But some sports testing is less about finding champions and more about exposing cheats. World anti-drug agencies strive - with varying degrees of success - to develop sophisticated tests to uncover athletes and coaches who are seeking an unfair chemical advantage.\n",
      "Technology has also revolutionised sports psychology. What gives players confidence, awareness, courage? How do players stop being complacent, fearful, nervous? Psychologists have learnt the answer is different for every athlete. Visualisation techniques, where players \"see\" a successful outcome before it happens, are practised by athletes at all levels.\n",
      "Managers and coaches increasingly use technology to help with tactics, in real time. In cricket, ball-tracking software helps bowlers find weaknesses in batting techniques. And in Australian Rules Football, live statistics help coaches find players who are getting beaten by their opponents.\n",
      "Motor sport is an industry almost entirely based on technology.  Grand Prix racing takes this to the furthest reaches, with competitors looking for any edge that will bring them faster  lap times measurable to one-thousandth of a second. Engine and chassis information is available in real time for drivers, team managers and  pit crews. This information is available to fans watching on television or on their computers or mobile devices.\n",
      "Consumers are the ultimate winners when innovations trickle down from elite competition. Motor sport has improved the efficiency and safety of road cars, and continues to be a test bed for technology. In the same way that disc brakes, advanced four-wheel drive systems and turbochargers were developed in the motor-sport crucible decades ago, the world's smartest engineers are refining hybrid engine technology, synthetic oils and fuels  to improve the cars we will drive in the future.\n",
      "This principle applies in all sports. The same state-of-the-art composite racquet Novak Djokovic used to win Wimbledon will win the mixed doubles final at the local tennis club. Golf equipment manufacturers, forced to abide by a strict set of global rules for elite and amateur players, endeavour to design clubs that help hackers hit the ball straighter and longer.\n",
      "What of the future?  Some say we're entering the age of 'smart wearables' technology, with athletes competing in outfits that transmit performance data in real time. Others believe  that nanotechnology will transform the way everyday sporting equipment is made, making it  stronger, lighter and easier to use. Hopefully, we will continue to be the beneficiaries of these advances, both as amateur competitors whose clothing and equipment are constantly improving, and as armchair fans whose enjoyment of sport is given a boost by the latest revolutionary technological advance.\n",
      "Learn more about BBC Storyworks Partnered content.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([para.get_text(strip=True) for para in soup.find_all('p')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.bbc.co.uk',\n",
       " 'https://www.bbc.co.uk/accessibility/',\n",
       " 'https://account.bbc.com/account',\n",
       " 'https://www.bbc.co.uk',\n",
       " 'https://www.bbc.co.uk/news']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sponsored_div = soup.find_all('div', attrs={'class':re.compile(\"sponsor|provided\")})\n",
    "links = soup.findAll('a', attrs={'href': re.compile(\"^https*:\\/\\/\")})\n",
    "#[j.find_all('div', attrs={'class':'item'}) for j in sponsored_div if j.find_all('div', attrs={'class':'item'})!=[]]\n",
    "[j.get('href') for j in links][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_frame = pd.read_csv('data/promotional_text.csv')\n",
    "except:\n",
    "    texts = []\n",
    "    urls = nativead[['Story 1', 'Story 2', 'Story 3']].to_numpy().flatten().tolist() + promo['URLs'].to_list()\n",
    "    good_urls = []\n",
    "    more_urls = []\n",
    "    badresponses = 0\n",
    "    for i, url in enumerate(urls):\n",
    "        if url=='nan':\n",
    "            texts.append('')\n",
    "            continue\n",
    "        try:\n",
    "            article = r.get(url, headers)\n",
    "            if article:\n",
    "                good_urls.append(url)\n",
    "                links = soup.select('body p > a')\n",
    "                data = article.text\n",
    "                soup = BeautifulSoup(data)\n",
    "                article = \" \".join([para.get_text(strip=True) for para in soup.find_all('p')])\n",
    "                texts.append(article)\n",
    "            else:\n",
    "                badresponses += 1\n",
    "                texts.append('')\n",
    "        except r.exceptions.TooManyRedirects:\n",
    "            texts.append('')\n",
    "            continue\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\r\" + f\"{i!s}/{len(urls)!s} with {badresponses!s} bad responses.\")\n",
    "    sources = nativead['Site'].repeat(3).to_list() + promo['source'].to_list()\n",
    "    final_frame = pd.DataFrame({'source':sources,\n",
    "                                'url': urls,\n",
    "                                'text': texts})\n",
    "    final_frame = final_frame[final_frame['text']!='']\n",
    "    final_frame = final_frame[final_frame['text']!=' ']\n",
    "    final_frame.to_csv('data/promotional_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC News \\r\\n</td>\n",
       "      <td>http://abcnews.go.com/Politics/obama-hits-trum...</td>\n",
       "      <td> -- \\r\\nPresidentObamasaid today that he does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News \\r\\n</td>\n",
       "      <td>http://abcnews.go.com/Politics/justice-antonin...</td>\n",
       "      <td> -- \\r\\nEven though the relatives and doctors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN Network</td>\n",
       "      <td>http://sponsorcontent.cnn.com/interactive/cine...</td>\n",
       "      <td>“Everything that needs to be said hasalready b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/this-designer-cut...</td>\n",
       "      <td>Watch live: NY Gov. Andrew Cuomo holds coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBC News Digital</td>\n",
       "      <td>http://www.nbcnews.com/video/baby-boomers-are-...</td>\n",
       "      <td>Watch live: NY Gov. Andrew Cuomo holds coronav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                                                url  \\\n",
       "0     ABC News \\r\\n  http://abcnews.go.com/Politics/obama-hits-trum...   \n",
       "1     ABC News \\r\\n  http://abcnews.go.com/Politics/justice-antonin...   \n",
       "2       CNN Network  http://sponsorcontent.cnn.com/interactive/cine...   \n",
       "3  NBC News Digital  http://www.nbcnews.com/video/this-designer-cut...   \n",
       "4  NBC News Digital  http://www.nbcnews.com/video/baby-boomers-are-...   \n",
       "\n",
       "                                                text  \n",
       "0   -- \\r\\nPresidentObamasaid today that he does...  \n",
       "1   -- \\r\\nEven though the relatives and doctors...  \n",
       "2  “Everything that needs to be said hasalready b...  \n",
       "3  Watch live: NY Gov. Andrew Cuomo holds coronav...  \n",
       "4  Watch live: NY Gov. Andrew Cuomo holds coronav...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('promotional_news_urls.txt', mode='w') as fileout:\n",
    "    fileout.write(\"\\n\".join(final_frame.url.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now assemble `ArticleVectors` straight-on, supplying one or both of the article text and the URL. This is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3 ms ± 1.84 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = fe.ArticleVector(text='sample text', url=test_url)\n",
    "x.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799 ms ± 87.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = fe.ArticleVector(url=test_url)\n",
    "x.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full disclosure: Due to limitations in the current version of `goose3` I am unable to properly handle `ReadTimeout` exceptions, which occur when an article takes longer than expected for `requests` to receive data from. I can arbitrarily extend the timeout threshold, but this of course means that each article will take even longer to extract. Instead I opt to use the text that I scraped using `BeautifulSoup` and **omit the article title** and Goose extraction altogether.\n",
    "\n",
    "This is of no consequence in the end -- the title is only used to determine a portion of an article's `all_caps_index` and `apa_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [fe.ArticleVector(text=row['text'], url=row['url']) for _, row in final_frame.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/promotional_news_vectors.txt', mode='w') as fileout:\n",
    "    fileout.write(\"\\n\".join([str(\" \".join(list(map(str, j.vector)) + ['9'])) for j in vectors]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to the NYTimes BBC Corrections dataset.\n",
    "\n",
    "I use a Powershell `cmdlet` originally obtained from [this source](http://woshub.com/powershell-get-folder-sizes/) to find those directories whose size is greater than 19.57Kb (the size of an empty Git repository). These then contain text snapshots of the first revisions of articles.\n",
    "\n",
    "```\n",
    "gci -force '.' -ErrorAction SilentlyContinue | \n",
    "    ? { ($_ -is [io.directoryinfo]) } | % {\n",
    "        $len = 0\n",
    "        gci -recurse -force $_.fullname -ErrorAction SilentlyContinue | \n",
    "           % { $len += $_.length}\n",
    "        $_.fullname, ', {0:N2}' -f ($len / 1Mb)\n",
    "} | Out-File -FilePath './nytbbcdirs.csv' -Encoding UTF8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = pd.read_csv(\"data/nytbbcdirs.csv\", encoding='utf-8', header=None, names=['dir', 'size'])\n",
    "folders = folders[folders['size'] > 19.57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hunter\\\\dev\\\\data\\\\nytimes_bbc_2017_2020\\\\2019-05_new'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = folders.max()['dir'].rstrip(\" \"); path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder found above is the most complete archive of the first revisions of corrected articles.\n",
    "\n",
    "We will [recursively open all bottom-level subfiles](https://stackoverflow.com/a/13617120) as text in the two URL directories. The second line is always article title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https_\\\\www.nytimes.com\\\\2019\\\\05\\\\01\\\\us\\\\college-admissions-scandal.html',\n",
       " 'www.bbc.co.uk\\\\news\\\\uk-politics-48360456',\n",
       " 'www.nytimes.com\\\\2019\\\\05\\\\06\\\\books\\\\review\\\\spring-ali-smith.html',\n",
       " 'www.nytimes.com\\\\2019\\\\05\\\\07\\\\business\\\\carbon-removal-technology-start-ups.html',\n",
       " 'www.bbc.co.uk\\\\news\\\\world-europe-48379620')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_set = set()\n",
    "for dir_, dirs, files in os.walk(path):\n",
    "    if '.git' in dirs:\n",
    "        dirs.remove('.git')\n",
    "    if '.gitignore' in files:\n",
    "        files.remove('.gitignore')\n",
    "    for file_name in files:\n",
    "        rel_dir = os.path.relpath(dir_, path)\n",
    "        rel_file = os.path.join(rel_dir, file_name)\n",
    "        file_set.add(rel_file)\n",
    "file_set = tuple(file_set); file_set[0:5]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, texts = [], []\n",
    "\n",
    "for file in file_set:\n",
    "    with open(os.path.join(path, file), mode='r', encoding = 'utf-8', errors='ignore') as filein:\n",
    "        text = filein.readlines()\n",
    "        texts.append(\" \".join(text[2:]))\n",
    "        titles.append(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = pd.DataFrame({'title':titles,\n",
    "                            'text':texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [\"url_ending_index\", \"from_reputable_source_index\",\n",
    "         \"today_index\", \"grammar_index\", \"quotation_index\",\n",
    "         \"past_tense_index\", \"present_tense_index\", \"should_index\",\n",
    "         \"opinion_index\", \"all_caps_index\", \"from_satire_source_index\",\n",
    "         \"exclamation_index\", \"apa_index\", \"name_source_index\",\n",
    "         \"interjection_index\", \"you_index\", \"dot_gov_ending_index\",\n",
    "         \"from_unreputable_source_index\", \"label\"]\n",
    "try:\n",
    "    corrections_vectors = pd.read_csv('./data/correction_news_vectors.txt', delim_whitespace=True, header=None, names=feats)\n",
    "except FileNotFoundError:\n",
    "    corrections_vectors = []\n",
    "\n",
    "    for i, row in corrections.iterrows():\n",
    "        sys.stdout.flush()\n",
    "        sys.stdout.write(\"\\r\" + f\"{i!s}/{len(file_set)}\")\n",
    "        corrections_vectors.append(fe.ArticleVector(text=row['text'], title=row['title']).vector)\n",
    "\n",
    "    corrections_vectors = pd.DataFrame(corrections_vectors, columns=feats)\n",
    "    corrections_vectors = corrections_vectors.assign(url_ending_index=1)\n",
    "    corrections_vectors = corrections_vectors.assign(dot_gov_ending_index=0)\n",
    "    corrections_vectors = corrections_vectors.assign(label=11)\n",
    "\n",
    "    corrections_vectors.to_csv('./data/correction_news_vectors.txt', header=None, index=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_ending_index</th>\n",
       "      <th>from_reputable_source_index</th>\n",
       "      <th>today_index</th>\n",
       "      <th>grammar_index</th>\n",
       "      <th>quotation_index</th>\n",
       "      <th>past_tense_index</th>\n",
       "      <th>present_tense_index</th>\n",
       "      <th>should_index</th>\n",
       "      <th>opinion_index</th>\n",
       "      <th>all_caps_index</th>\n",
       "      <th>from_satire_source_index</th>\n",
       "      <th>exclamation_index</th>\n",
       "      <th>apa_index</th>\n",
       "      <th>name_source_index</th>\n",
       "      <th>interjection_index</th>\n",
       "      <th>you_index</th>\n",
       "      <th>dot_gov_ending_index</th>\n",
       "      <th>from_unreputable_source_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.074656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052063</td>\n",
       "      <td>0.075147</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099256</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111663</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061181</td>\n",
       "      <td>0.072785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113924</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.035443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093671</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_ending_index  from_reputable_source_index  today_index  grammar_index  \\\n",
       "0                 1                            0     0.000491       0.074656   \n",
       "1                 1                            0     0.000000       0.061208   \n",
       "2                 1                            0     0.001984       0.063492   \n",
       "3                 1                            0     0.000000       0.040084   \n",
       "4                 1                            0     0.005063       0.035443   \n",
       "\n",
       "   quotation_index  past_tense_index  present_tense_index  should_index  \\\n",
       "0              0.0          0.052063             0.075147      0.000982   \n",
       "1              0.0          0.099256             0.064516      0.001654   \n",
       "2              0.0          0.041667             0.069444      0.000000   \n",
       "3              0.0          0.061181             0.072785      0.000000   \n",
       "4              0.0          0.093671             0.043038      0.000000   \n",
       "\n",
       "   opinion_index  all_caps_index  from_satire_source_index  exclamation_index  \\\n",
       "0              0        0.006876                         1           0.000000   \n",
       "1              0        0.008271                         1           0.000000   \n",
       "2              0        0.037698                         1           0.000000   \n",
       "3              0        0.004219                         1           0.001055   \n",
       "4              0        0.007595                         1           0.000000   \n",
       "\n",
       "   apa_index  name_source_index  interjection_index  you_index  \\\n",
       "0          1           0.162574            0.000491   0.005403   \n",
       "1          0           0.111663            0.000827   0.004136   \n",
       "2          0           0.253968            0.000000   0.007937   \n",
       "3          1           0.113924            0.001055   0.003165   \n",
       "4          0           0.230380            0.000000   0.000000   \n",
       "\n",
       "   dot_gov_ending_index  from_unreputable_source_index  label  \n",
       "0                     0                              0     11  \n",
       "1                     0                              0     11  \n",
       "2                     0                              0     11  \n",
       "3                     0                              0     11  \n",
       "4                     0                              0     11  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrections_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
